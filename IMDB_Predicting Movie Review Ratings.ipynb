{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stage\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 132s 5ms/step - loss: 0.4579 - acc: 0.7838 - val_loss: 0.4075 - val_acc: 0.8218\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 128s 5ms/step - loss: 0.3015 - acc: 0.8782 - val_loss: 0.3798 - val_acc: 0.8328\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 127s 5ms/step - loss: 0.2196 - acc: 0.9122 - val_loss: 0.4127 - val_acc: 0.8215\n",
      "Test performance: accuracy=0.82152, loss=0.4127060862159729\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jskDr/keraspp\n",
    "# nb_ex5_1_lstm_imdb_cl.ipynb\n",
    "\n",
    "# IMDB dataset : http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "\"\"\"imdb is a dataset in which the words in the review sentence \n",
    "are sorted in order of appearance frequency, and \n",
    "the sequence that converts the word to an integer is x \n",
    "and the evaluation is positive or negative.\n",
    "y is recorded as 1 (positive) or 2 (negative).\n",
    "Our goal is to predict y with x.\n",
    "\"\"\"\n",
    "#-*- coding: utf-8 -*-\n",
    " \n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers, models, datasets\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "\"\"\"We call the imdb dataset with datasets.imdb.load_data(). \n",
    "If (num_words = max_features) is set, only num_words word \n",
    "types will be fetched(imported,loaded) in the order of the most frequently \n",
    "occurring words(the order of appearance frequency), \n",
    "otherwise they will be replaced with oov_char values.\n",
    "\n",
    "preprocessing.sequence.pad_sequences serves to equalize the lengths of the sequences.\n",
    "\"\"\"\n",
    "class Data:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        (x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(\n",
    "            num_words=max_features)\n",
    "        x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "        x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    " \n",
    "class RNN_LSTM(models.Model):\n",
    "    def __init__(self, max_features, maxlen):\n",
    "        x = layers.Input((maxlen,))  # 80,20000 == length,features\n",
    "        h = layers.Embedding(max_features, 128)(x)  # features 20000(0~19999) ===> 128 embedding \n",
    "        h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "        y = layers.Dense(1, activation='sigmoid')(h)\n",
    "        super().__init__(x, y)\n",
    " \n",
    "        self.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "class Machine:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        self.data = Data(max_features, maxlen)\n",
    "        self.model = RNN_LSTM(max_features, maxlen)\n",
    " \n",
    "    def run(self, epochs=3, batch_size=32):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    " \n",
    "        print('Training stage')\n",
    "        model.fit(data.x_train, data.y_train,\n",
    "            batch_size=batch_size, epochs=epochs,\n",
    "            validation_data=(data.x_test, data.y_test),\n",
    "            verbose=1)\n",
    " \n",
    "        loss, acc = model.evaluate(data.x_test, data.y_test,\n",
    "            batch_size=batch_size, verbose=2)\n",
    " \n",
    "        print('Test performance: accuracy={0}, loss={1}'.format(acc, loss))\n",
    " \n",
    "def main():\n",
    "    m = Machine()\n",
    "    m.run()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
